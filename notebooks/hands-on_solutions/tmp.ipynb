{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intake Catalog\n",
    "Similar to the shopping catalog at your favorite online bookstore, the intake catalog contains information (e.g. model, variables, and time range) about each dataset (the title, author, and number of pages of the book, for instance) that you can access before loading the data. It means that thanks to the catalog, you can find where is the book just by using some keywords and you do not need to hold it in your hand to know the number of pages, for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Intake Catalog\n",
    "We load the catalog descriptor with the intake package. The catalog is updated daily. The catalog descriptor is created by the DKRZ developers that manage the catalog, you do not need to care so much about it, knowing where it is and loading it is enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to catalog descriptor on the DKRZ server\n",
    "col_url = \"/work/ik1017/Catalogs/mistral-cmip6.json\"\n",
    "\n",
    "# Open the catalog with the intake package and name it \"col\" as short for \"collection\"\n",
    "col = intake.open_esm_datastore(col_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is inside the intake catalog. The underlying data base is given as a pandas dataframe which we can access with \"col.df\". Then, \"col.df.head()\" shows us the first rows of the table of the catalog.\n",
    "\n",
    "This catalog contains all datasets of the CMIP6 archive at DKRZ. In the next step we narrow the results down by chosing a model and variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse the Intake Catalog\n",
    "In this example we chose the Max-Planck Earth System Model in High Resolution Mode (\"MPI-ESM1-2-HR\") and the maximum temperature near surface (\"tasmax\") as variable. We also choose an experiment. CMIP6 comprises several kind of experiments. Each experiment has various simulation members. you can find more information in the [CMIP6 Model and Experiment Documentation](https://pcmdi.llnl.gov/CMIP6/Guide/dataUsers.html#5-model-and-experiment-documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how we tell intake what data we want\n",
    "\n",
    "query = dict(\n",
    "    source_id      = \"MPI-ESM1-2-LR\", # the model \n",
    "    variable_id    = \"tasmax\", # temperature at surface, maximum\n",
    "    table_id       = \"day\", # daily maximum\n",
    "    experiment_id  = \"historical\", # what we selected in the drop down menu,e.g. SSP2.4-5 2015-2100\n",
    "    member_id      = \"r10i1p1f1\", # \"r\" realization, \"i\" initialization, \"p\" physics, \"f\" forcing\n",
    ")\n",
    "\n",
    "# Intake looks for the query we just defined in the catalog of the CMIP6 data pool at DKRZ\n",
    "cat = col.search(**query)\n",
    "\n",
    "# Show query results\n",
    "cat.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "Now, it would be time for the analysis of the data. As this notebook focuses only on intake, we recommend reading `use-case_frost_days_intake_xarray_cmip6.ipynb`, `use-case_multimodel_comparison_xarray_cdo_cmip6.ipynb`, `use-case_summer_days_intake_xarray_cmip6.ipynb` or `use-case_tropical_nights_intake_xarray_cmip6.ipynb` for more information on data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Selection\n",
    "In order to use the exact same data collection at a later point, you can save your collection. For this, you need to specify a location and a file name. The collection will be saved as human readable `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File Location\n",
    "file_loc = '.'\n",
    "file_name = 'my_col'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.df.to_csv(file_loc +'/' +file_name +'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Saved Selection\n",
    "You can access your saved collection by reading the `.csv` file with `pd.read_csv(<file location>/<file name>)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col = pd.read_csv(file_loc +'/' +file_name +'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can view your saved collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
